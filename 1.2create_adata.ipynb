{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053b9734-7e1f-4d63-8b0c-faf50ac9648f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 CSV files\n",
      "Reading MS00000915_R0_Cell Membrane.csv...\n",
      "Reading MS00000915_R1_Cell Membrane.csv...\n",
      "Reading MS00000917_R0_Cell Membrane.csv...\n",
      "Reading MS00000917_R1_Cell Membrane.csv...\n",
      "Reading MS00000919_R0_Cell Membrane.csv...\n",
      "Reading MS00000919_R1_Cell Membrane.csv...\n",
      "Reading MS00000921_R0_Cell Membrane.csv...\n",
      "Reading MS00000921_R1_Cell Membrane.csv...\n",
      "Reading MS00000923_R0_Cell Membrane.csv...\n",
      "Reading MS00000923_R1_Cell Membrane.csv...\n",
      "Reading MS00000925_R0_Cell Membrane.csv...\n",
      "Reading MS00000925_R1_Cells_Cell Membrane.csv...\n",
      "Reading MS00000927_R0_Cell Membrane.csv...\n",
      "Reading MS00000927_R1_Cell Membrane.csv...\n",
      "Reading MS00000929_R0_Cell Membrane.csv...\n",
      "Reading MS00000929_R1_Cell Membrane.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3803/3858020634.py:16: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MS00000931_R0_Cells_Cell Membrane.csv...\n",
      "Reading MS00000931_R1_Cell Membrane.csv...\n",
      "Reading MS00000933_R0_Cell Membrane.csv...\n",
      "Reading MS00000933_R1_Cell Membrane.csv...\n",
      "Reading MS00000935_R0_Cell Membrane.csv...\n",
      "Reading MS00000935_R1_Cell Membrane.csv...\n",
      "Reading MS00000937_R0_Cell Membrane.csv...\n",
      "Reading MS00000937_R1_Cell Membrane.csv...\n",
      "Reading MS00000939_R0_Cells_Cell Membrane.csv...\n",
      "Reading MS00000939_R1_Cell Membrane.csv...\n",
      "Reading MS00000941_R0_Cell Membrane.csv...\n",
      "Reading MS00000943_R0_Cell Membrane.csv...\n",
      "Reading MS00000943_R1_Cell Membrane.csv...\n",
      "Reading MS00000945_R0_Cell Membrane.csv...\n",
      "Reading MS00000945_R1_Cell Membrane.csv...\n",
      "Reading MS00000947_R0_Cell Membrane.csv...\n",
      "Reading MS00000947_R1_Cell Membrane.csv...\n",
      "Reading MS00000949_R0_Cells_Cell Membrane.csv...\n",
      "Reading MS00000949_R1_Cells_Cell Membrane.csv...\n",
      "Reading MS00000951_R0_Cell Membrane.csv...\n",
      "Reading MS00000951_R1_Cell Membrane.csv...\n",
      "Reading MS00000953_R0_Cell Membrane.csv...\n",
      "Reading MS00000953_R1_Cell Membrane.csv...\n",
      "Reading MS00000955_R1_Cells_Cell Membrane.csv...\n",
      "Reading MS00000957_R0_Cell Membrane.csv...\n",
      "Reading MS00000957_R1_Cell Membrane.csv...\n",
      "Reading MS00000959_R0_Set_Cell Membrane.csv...\n",
      "Reading MS00000959_R1_Cells_Cell Membrane.csv...\n",
      "Reading MS00000961_R0_Cell Membrane.csv...\n",
      "Reading MS00000961_R1_Cell Membrane.csv...\n",
      "Reading MS00000963_R0_Cells_Cell Membrane.csv...\n",
      "Reading MS00000963_R1_Cell Membrane.csv...\n",
      "Reading MS00000965_R0_Cells_Cell Membrane.csv...\n",
      "Reading MS00000965_R1_Cell Membrane.csv...\n",
      "\n",
      "Total cells across all samples: 3205629\n",
      "\n",
      "Found 60 mean intensity columns (before filtering)\n",
      "\n",
      "âž• Marker groups to combine:\n",
      "  pSTAT3Y705-D3A7AF555:\n",
      "    - pSTAT3Y705-D3A7AF555\n",
      "    - pSTAT3Y705-D3A7AF5555\n",
      "\n",
      "âš ï¸  Removed 6 marker(s):\n",
      "    - DAPI_AF_R01 (removed DAPI)\n",
      "    - pSTAT3Y705-D3A7AF555 (excluded)\n",
      "    - T-bet-E4I2KAF555 (2) (duplicate)\n",
      "    - pSTAT1s727-D3B7AF647 (2) (duplicate)\n",
      "    - CD123-IL3RAAF750 (excluded)\n",
      "    - DAPI_R15 (removed DAPI)\n",
      "\n",
      "Kept 54 markers (before combining)\n",
      "\n",
      "âž• Summing marker groups:\n",
      "\n",
      "================================================================================\n",
      "NaN VALUE FILTERING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ANNDATA OBJECT SUMMARY\n",
      "================================================================================\n",
      "AnnData object with n_obs Ã— n_vars = 3205629 Ã— 53\n",
      "    obs: 'cell_id', 'sample_id', 'Timeframe', 'batch_id', 'x', 'y', 'Outline Area (ÂµmÂ²)', 'Perimeter (Âµm)', 'Circularity'\n",
      "    var: 'marker_name'\n",
      "    layers: 'intensity_mean', 'intensity_median', 'intensity_std'\n",
      "\n",
      "Layers: ['intensity_mean', 'intensity_median', 'intensity_std']\n",
      "\n",
      "Batches: ['MS00000915' 'MS00000917' 'MS00000919' 'MS00000921' 'MS00000923'\n",
      " 'MS00000925' 'MS00000927' 'MS00000929' 'MS00000931' 'MS00000933'\n",
      " 'MS00000935' 'MS00000937' 'MS00000939' 'MS00000941' 'MS00000943'\n",
      " 'MS00000945' 'MS00000947' 'MS00000949' 'MS00000951' 'MS00000953'\n",
      " 'MS00000955' 'MS00000957' 'MS00000959' 'MS00000961' 'MS00000963'\n",
      " 'MS00000965']\n",
      "\n",
      "Samples: ['MS00000915_R0' 'MS00000915_R1' 'MS00000917_R0' 'MS00000917_R1'\n",
      " 'MS00000919_R0' 'MS00000919_R1' 'MS00000921_R0' 'MS00000921_R1'\n",
      " 'MS00000923_R0' 'MS00000923_R1' 'MS00000925_R0' 'MS00000925_R1'\n",
      " 'MS00000927_R0' 'MS00000927_R1' 'MS00000929_R0' 'MS00000929_R1'\n",
      " 'MS00000931_R0' 'MS00000931_R1' 'MS00000933_R0' 'MS00000933_R1'\n",
      " 'MS00000935_R0' 'MS00000935_R1' 'MS00000937_R0' 'MS00000937_R1'\n",
      " 'MS00000939_R0' 'MS00000939_R1' 'MS00000941_R0' 'MS00000943_R0'\n",
      " 'MS00000943_R1' 'MS00000945_R0' 'MS00000945_R1' 'MS00000947_R0'\n",
      " 'MS00000947_R1' 'MS00000949_R0' 'MS00000949_R1' 'MS00000951_R0'\n",
      " 'MS00000951_R1' 'MS00000953_R0' 'MS00000953_R1' 'MS00000955_R1'\n",
      " 'MS00000957_R0' 'MS00000957_R1' 'MS00000959_R0' 'MS00000959_R1'\n",
      " 'MS00000961_R0' 'MS00000961_R1' 'MS00000963_R0' 'MS00000963_R1'\n",
      " 'MS00000965_R0' 'MS00000965_R1']\n",
      "Number of cells: 3205629\n",
      "Number of markers: 53\n",
      "\n",
      "âœ“ Saved to combined_data_0020226.h5ad\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "\n",
    "# Path to your folder with CSVs\n",
    "folder_path = '/home/workspace/private/CSVs'\n",
    "# Get all CSV files\n",
    "csv_files = list(Path(folder_path).glob('*.csv'))\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "# List to store dataframes\n",
    "all_dfs = []\n",
    "# Read each CSV and add sample_id and batch_id based on filename\n",
    "for csv_file in csv_files:\n",
    "    print(f\"Reading {csv_file.name}...\")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Extract from filename\n",
    "    parts = csv_file.stem.split('_')\n",
    "    batch_id = parts[0]\n",
    "    sample_id = '_'.join(parts[:2]) if len(parts) >= 2 else parts[0]\n",
    "    \n",
    "    df['sample_id'] = sample_id\n",
    "    df['batch_id'] = batch_id\n",
    "    \n",
    "    all_dfs.append(df)\n",
    "    \n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "print(f\"\\nTotal cells across all samples: {len(combined_df)}\")\n",
    "\n",
    "# Get marker columns for all three intensity types\n",
    "mean_columns = [col for col in combined_df.columns if col.startswith('Mean Intensity - ')]\n",
    "median_columns = [col for col in combined_df.columns if col.startswith('Median Intensity - ')]\n",
    "std_columns = [col for col in combined_df.columns if col.startswith('Standard Deviation Intensity - ')]\n",
    "\n",
    "print(f\"\\nFound {len(mean_columns)} mean intensity columns (before filtering)\")\n",
    "\n",
    "# Extract marker names\n",
    "marker_names_raw = [col.replace('Mean Intensity - ', '') for col in mean_columns]\n",
    "\n",
    "# Define markers to exclude\n",
    "markers_to_exclude = ['CD123-IL3RAAF750','pSTAT3Y705-D3A7AF555']\n",
    "'''\n",
    "# Define marker groups to combine\n",
    "marker_groups_to_combine = {\n",
    "    'pSTAT3Y705-D3A7AF555': ['pSTAT3Y705-D3A7AF555', 'pSTAT3Y705-D3A7AF5555']  # Combine typo with correct\n",
    "}\n",
    "'''\n",
    "\n",
    "# Define markers to remove completely (DAPI markers)\n",
    "markers_to_remove = ['DAPI_R15', 'DAPI_AF_R01']\n",
    "#['DAPI_R14', 'DAPI_R15', 'DAPI_AF_R01']\n",
    "\n",
    "# Show what will be combined\n",
    "print(\"\\nâž• Marker groups to combine:\")\n",
    "for combined_name, group_markers in marker_groups_to_combine.items():\n",
    "    print(f\"  {combined_name}:\")\n",
    "    for m in group_markers:\n",
    "        print(f\"    - {m}\")\n",
    "\n",
    "# Filter out markers ending with ' (2)' OR in the exclusion list OR in the removal list\n",
    "markers_to_keep_mask = [\n",
    "    not name.endswith(' (2)') and name not in markers_to_exclude and name not in markers_to_remove\n",
    "    for name in marker_names_raw\n",
    "]\n",
    "\n",
    "# Get the filtered marker names and columns\n",
    "marker_names_filtered = [name for name, keep in zip(marker_names_raw, markers_to_keep_mask) if keep]\n",
    "mean_columns_filtered = [col for col, keep in zip(mean_columns, markers_to_keep_mask) if keep]\n",
    "median_columns_filtered = [col for col, keep in zip(median_columns, markers_to_keep_mask) if keep]\n",
    "std_columns_filtered = [col for col, keep in zip(std_columns, markers_to_keep_mask) if keep]\n",
    "\n",
    "# Report what was removed\n",
    "removed_markers = [name for name, keep in zip(marker_names_raw, markers_to_keep_mask) if not keep]\n",
    "if removed_markers:\n",
    "    print(f\"\\nâš ï¸  Removed {len(removed_markers)} marker(s):\")\n",
    "    for marker in removed_markers:\n",
    "        if marker.endswith(' (2)'):\n",
    "            print(f\"    - {marker} (duplicate)\")\n",
    "        elif marker in markers_to_exclude:\n",
    "            print(f\"    - {marker} (excluded)\")\n",
    "        elif marker in markers_to_remove:\n",
    "            print(f\"    - {marker} (removed DAPI)\")\n",
    "\n",
    "print(f\"\\nKept {len(mean_columns_filtered)} markers (before combining)\")\n",
    "\n",
    "# Now combine marker groups by SUMMING\n",
    "print(f\"\\nâž• Summing marker groups:\")\n",
    "final_marker_names = []\n",
    "final_mean_data = []\n",
    "final_median_data = []\n",
    "final_std_data = []\n",
    "\n",
    "# Track which markers have been combined\n",
    "markers_already_combined = set()\n",
    "for group_markers in marker_groups_to_combine.values():\n",
    "    markers_already_combined.update(group_markers)\n",
    "\n",
    "# Process each marker\n",
    "for i, marker_name in enumerate(marker_names_filtered):\n",
    "    # Check if this marker should be combined\n",
    "    combined = False\n",
    "    for combined_name, group_markers in marker_groups_to_combine.items():\n",
    "        if marker_name in group_markers:\n",
    "            # Only process this group once (when we encounter the first marker in the group)\n",
    "            if marker_name == group_markers[0]:\n",
    "                print(f\"\\n  Summing {len(group_markers)} markers into '{combined_name}':\")\n",
    "                for m in group_markers:\n",
    "                    print(f\"    - {m}\")\n",
    "                \n",
    "                # Find all columns for this group across the three intensity types\n",
    "                group_mean_cols = []\n",
    "                group_median_cols = []\n",
    "                group_std_cols = []\n",
    "                \n",
    "                for m in group_markers:\n",
    "                    if m in marker_names_filtered:\n",
    "                        idx = marker_names_filtered.index(m)\n",
    "                        group_mean_cols.append(mean_columns_filtered[idx])\n",
    "                        group_median_cols.append(median_columns_filtered[idx])\n",
    "                        group_std_cols.append(std_columns_filtered[idx])\n",
    "                \n",
    "                # Sum the values across all markers in the group\n",
    "                if group_mean_cols:\n",
    "                    mean_data = combined_df[group_mean_cols].values\n",
    "                    median_data = combined_df[group_median_cols].values\n",
    "                    std_data = combined_df[group_std_cols].values\n",
    "                    \n",
    "                    print(f\"    âœ“ Found and summed {len(group_mean_cols)} columns\")\n",
    "                    \n",
    "                    final_marker_names.append(combined_name)\n",
    "                    final_mean_data.append(np.sum(mean_data, axis=1))\n",
    "                    final_median_data.append(np.sum(median_data, axis=1))\n",
    "                    final_std_data.append(np.sum(std_data, axis=1))\n",
    "                else:\n",
    "                    print(f\"    âš ï¸  Warning: No columns found for this group!\")\n",
    "            \n",
    "            combined = True\n",
    "            break\n",
    "    \n",
    "    # If not part of a combined group, keep as is\n",
    "    if not combined:\n",
    "        final_marker_names.append(marker_name)\n",
    "        final_mean_data.append(combined_df[mean_columns_filtered[i]].values)\n",
    "        final_median_data.append(combined_df[median_columns_filtered[i]].values)\n",
    "        final_std_data.append(combined_df[std_columns_filtered[i]].values)\n",
    "\n",
    "# Convert lists to arrays\n",
    "X_mean = np.column_stack(final_mean_data)\n",
    "X_median = np.column_stack(final_median_data)\n",
    "X_std = np.column_stack(final_std_data)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"NaN VALUE FILTERING\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "'''\n",
    "# Check for NaN values in each marker across all intensity types\n",
    "markers_with_nans = []\n",
    "for i, marker in enumerate(final_marker_names):\n",
    "    mean_nans = np.sum(np.isnan(X_mean[:, i]))\n",
    "    median_nans = np.sum(np.isnan(X_median[:, i]))\n",
    "    std_nans = np.sum(np.isnan(X_std[:, i]))\n",
    "    total_nans = mean_nans + median_nans + std_nans\n",
    "    \n",
    "    if total_nans > 0:\n",
    "        pct_mean = (mean_nans / len(X_mean[:, i])) * 100\n",
    "        pct_median = (median_nans / len(X_median[:, i])) * 100\n",
    "        pct_std = (std_nans / len(X_std[:, i])) * 100\n",
    "        \n",
    "        markers_with_nans.append({\n",
    "            'marker': marker,\n",
    "            'mean_nans': mean_nans,\n",
    "            'median_nans': median_nans,\n",
    "            'std_nans': std_nans,\n",
    "            'total_nans': total_nans,\n",
    "            'pct_mean': pct_mean,\n",
    "            'pct_median': pct_median,\n",
    "            'pct_std': pct_std\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nâš ï¸  Marker: {marker}\")\n",
    "        print(f\"    Mean NaNs:   {mean_nans:>8,} ({pct_mean:>6.2f}%)\")\n",
    "        print(f\"    Median NaNs: {median_nans:>8,} ({pct_median:>6.2f}%)\")\n",
    "        print(f\"    Std NaNs:    {std_nans:>8,} ({pct_std:>6.2f}%)\")\n",
    "\n",
    "if markers_with_nans:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Found {len(markers_with_nans)} markers with NaN values\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Decision: Remove markers that are mostly NaN (>90% in mean intensity)\n",
    "    markers_to_remove_nan = [m['marker'] for m in markers_with_nans if m['pct_mean'] > 90]\n",
    "    \n",
    "    if markers_to_remove_nan:\n",
    "        print(f\"\\nðŸ—‘ï¸  Removing {len(markers_to_remove_nan)} markers with >90% NaN values:\")\n",
    "        for marker in markers_to_remove_nan:\n",
    "            print(f\"    - {marker}\")\n",
    "        \n",
    "        # Filter out markers with >90% NaNs\n",
    "        markers_to_keep_idx = [i for i, marker in enumerate(final_marker_names) \n",
    "                               if marker not in markers_to_remove_nan]\n",
    "        \n",
    "        X_mean = X_mean[:, markers_to_keep_idx]\n",
    "        X_median = X_median[:, markers_to_keep_idx]\n",
    "        X_std = X_std[:, markers_to_keep_idx]\n",
    "        final_marker_names = [final_marker_names[i] for i in markers_to_keep_idx]\n",
    "        \n",
    "        print(f\"\\nâœ“ Markers remaining after NaN filtering: {len(final_marker_names)}\")\n",
    "    \n",
    "    # For remaining markers with some NaNs, replace NaN with 0\n",
    "    markers_with_partial_nans = [m['marker'] for m in markers_with_nans \n",
    "                                  if m['marker'] not in markers_to_remove_nan]\n",
    "    \n",
    "    if markers_with_partial_nans:\n",
    "        print(f\"\\nðŸ”§ Replacing NaN with 0 for {len(markers_with_partial_nans)} markers with partial NaN values:\")\n",
    "        for marker in markers_with_partial_nans:\n",
    "            marker_idx = final_marker_names.index(marker)\n",
    "            \n",
    "            mean_nans_before = np.sum(np.isnan(X_mean[:, marker_idx]))\n",
    "            median_nans_before = np.sum(np.isnan(X_median[:, marker_idx]))\n",
    "            std_nans_before = np.sum(np.isnan(X_std[:, marker_idx]))\n",
    "            \n",
    "            # Replace NaN with 0\n",
    "            X_mean[:, marker_idx] = np.nan_to_num(X_mean[:, marker_idx], nan=0.0)\n",
    "            X_median[:, marker_idx] = np.nan_to_num(X_median[:, marker_idx], nan=0.0)\n",
    "            X_std[:, marker_idx] = np.nan_to_num(X_std[:, marker_idx], nan=0.0)\n",
    "            \n",
    "            print(f\"    - {marker}: {mean_nans_before + median_nans_before + std_nans_before:,} NaNs â†’ 0\")\n",
    "else:\n",
    "    print(\"\\nâœ“ No NaN values found in any markers\")\n",
    "\n",
    "# Verify no NaNs remain\n",
    "total_nans_remaining = np.sum(np.isnan(X_mean)) + np.sum(np.isnan(X_median)) + np.sum(np.isnan(X_std))\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"NaN verification: {total_nans_remaining} NaN values remaining across all data\")\n",
    "print(f\"{'='*80}\")\n",
    "'''\n",
    "'''\n",
    "# Remove outliers using stricter IQR method (2.0 instead of 1.5) for each marker\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Removing outliers using stricter IQR method (values > Q3 + 2.0*IQR)...\")\n",
    "print(f\"{'='*80}\")\n",
    "for i, marker in enumerate(final_marker_names):\n",
    "    # Calculate IQR and outlier threshold for each intensity type\n",
    "    for X, name in [(X_mean, 'mean'), (X_median, 'median'), (X_std, 'std')]:\n",
    "        q1 = np.percentile(X[:, i], 25)\n",
    "        q3 = np.percentile(X[:, i], 75)\n",
    "        iqr = q3 - q1\n",
    "        upper_threshold = q3 + 2.0 * iqr  # Changed from 1.5 to 2.0\n",
    "        \n",
    "        # Count outliers before capping\n",
    "        n_outliers = np.sum(X[:, i] > upper_threshold)\n",
    "        \n",
    "        # Cap values at upper threshold\n",
    "        if name == 'mean':\n",
    "            X_mean[:, i] = np.where(X_mean[:, i] > upper_threshold, upper_threshold, X_mean[:, i])\n",
    "        elif name == 'median':\n",
    "            X_median[:, i] = np.where(X_median[:, i] > upper_threshold, upper_threshold, X_median[:, i])\n",
    "        else:\n",
    "            X_std[:, i] = np.where(X_std[:, i] > upper_threshold, upper_threshold, X_std[:, i])\n",
    "        \n",
    "        if n_outliers > 0 and name == 'mean':  # Only print once per marker\n",
    "            pct_outliers = (n_outliers / len(X[:, i])) * 100\n",
    "            print(f\"  {marker}: {n_outliers} cells ({pct_outliers:.2f}%) capped at {upper_threshold:.2f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Final marker count: {len(final_marker_names)}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nFinal markers:\")\n",
    "for m in final_marker_names:\n",
    "    print(f\"  - {m}\")\n",
    "\n",
    "'''\n",
    "\n",
    "# Create obs DataFrame\n",
    "obs = pd.DataFrame({\n",
    "    'cell_id': combined_df['ID'].astype(str) + '_' + combined_df['sample_id'],\n",
    "    'sample_id': combined_df['sample_id'],\n",
    "    'Timeframe': combined_df['Timeframe'].astype(str),\n",
    "    'batch_id': combined_df['batch_id'],\n",
    "    'x': combined_df['Centroid X (Âµm)'],\n",
    "    'y': combined_df['Centroid Y (Âµm)'],\n",
    "    'Outline Area (ÂµmÂ²)': combined_df['Outline Area (ÂµmÂ²)'],\n",
    "    'Perimeter (Âµm)': combined_df['Perimeter (Âµm)'],\n",
    "    'Circularity': combined_df['Circularity']\n",
    "})\n",
    "obs.index = obs['cell_id']\n",
    "\n",
    "# Create var DataFrame with clean marker names\n",
    "var = pd.DataFrame({\n",
    "    'marker_name': final_marker_names\n",
    "})\n",
    "var.index = final_marker_names\n",
    "\n",
    "# Create AnnData object with mean as main matrix\n",
    "adata = ad.AnnData(X=X_mean, obs=obs, var=var)\n",
    "\n",
    "# Add all three intensity measures as layers\n",
    "adata.layers['intensity_mean'] = X_mean\n",
    "adata.layers['intensity_median'] = X_median\n",
    "adata.layers['intensity_std'] = X_std\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"ANNDATA OBJECT SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(adata)\n",
    "print(f\"\\nLayers: {list(adata.layers.keys())}\")\n",
    "print(f\"\\nBatches: {adata.obs['batch_id'].unique()}\")\n",
    "print(f\"\\nSamples: {adata.obs['sample_id'].unique()}\")\n",
    "print(f\"Number of cells: {adata.n_obs}\")\n",
    "print(f\"Number of markers: {adata.n_vars}\")\n",
    "\n",
    "# Save the AnnData object\n",
    "output_filename = 'combined_data_0020226.h5ad'\n",
    "adata.write(output_filename)\n",
    "print(f\"\\nâœ“ Saved to {output_filename}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33e66ede-c460-41fa-b5d2-9d5f7d6b844c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs Ã— n_vars = 3205629 Ã— 53\n",
       "    obs: 'cell_id', 'sample_id', 'Timeframe', 'batch_id', 'x', 'y', 'Outline Area (ÂµmÂ²)', 'Perimeter (Âµm)', 'Circularity'\n",
       "    var: 'marker_name'\n",
       "    layers: 'intensity_mean', 'intensity_median', 'intensity_std'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a70ab6-a88c-46a8-82c4-d7bb0bb2317c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 pSTAT markers:\n",
      "  - pSTAT3Y705-D3A7AF555\n",
      "  - pSTAT1Ty70158D6AF647\n",
      "  - pSTAT1s727-D3B7AF647\n",
      "\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "MARKER COMPLETENESS ASSESSMENT: pSTAT3Y705-D3A7AF555\n",
      "============================================================\n",
      "Layer used: intensity_mean\n",
      "\n",
      "Overall Statistics:\n",
      "  Total cells:      3,104,607\n",
      "  Zero values:              0 (0.00%)\n",
      "  NaN values:       3,104,607 (100.00%)\n",
      "  Negative values:          0\n",
      "  Positive values:          0 (0.00%)\n",
      "\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "MARKER COMPLETENESS ASSESSMENT: pSTAT1Ty70158D6AF647\n",
      "============================================================\n",
      "Layer used: intensity_mean\n",
      "\n",
      "Overall Statistics:\n",
      "  Total cells:      3,104,607\n",
      "  Zero values:            392 (0.01%)\n",
      "  NaN values:               8 (0.00%)\n",
      "  Negative values:          0\n",
      "  Positive values:  3,104,207 (99.99%)\n",
      "\n",
      "Positive Value Statistics:\n",
      "  Min:    0.0093\n",
      "  Max:    65514.1346\n",
      "  Mean:   315.0810\n",
      "  Median: 265.0580\n",
      "\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "MARKER COMPLETENESS ASSESSMENT: pSTAT1s727-D3B7AF647\n",
      "============================================================\n",
      "Layer used: intensity_mean\n",
      "\n",
      "Overall Statistics:\n",
      "  Total cells:      3,104,607\n",
      "  Zero values:            229 (0.01%)\n",
      "  NaN values:               9 (0.00%)\n",
      "  Negative values:          0\n",
      "  Positive values:  3,104,369 (99.99%)\n",
      "\n",
      "Positive Value Statistics:\n",
      "  Min:    0.0084\n",
      "  Max:    65518.0298\n",
      "  Mean:   273.4247\n",
      "  Median: 224.3450\n"
     ]
    }
   ],
   "source": [
    "#COMMENT/EXPLAIN\n",
    "all_pstat_results = assess_all_pstat_markers(adata, sample_col='marker_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d411e39-636d-4554-892b-0715282ce596",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scanpyv2)",
   "language": "python",
   "name": "python-scanpyv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
